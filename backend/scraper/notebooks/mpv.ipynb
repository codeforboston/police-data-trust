{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Mapping Police Violence (MPV) Data Into the NPDC Index\n",
    "\n",
    "This notebook loads the [Mapping Police Violence](https://mappingpoliceviolence.org) dataset into the app. \n",
    "\n",
    "Run this whenever the dataset changes to pull in the latest data. Existing rows are ignored.  \n",
    "\n",
    "## Setup\n",
    "\n",
    "Install project dependencies and Jupyter:\n",
    "\n",
    "```bash\n",
    "pip3 install jupyter\n",
    "pip3 install -r requirements/dev_unix.txt\n",
    "```\n",
    "\n",
    "The database should be running and the tables should be up to date. You can use docker to reset the application to a clean state: \n",
    "\n",
    "```bash\n",
    "# Stop services and remove volumes, rebuild images, start the database, create tables, run seeds, and follow logs\n",
    "docker-compose down -v && docker-compose up --build -d db api && docker-compose logs -f\n",
    "```\n",
    "\n",
    "Then open the notebook with either [VSCode](https://code.visualstudio.com/) or `jupyter notebook`.\n",
    "\n",
    "You can run the notebook from the command line as well:\n",
    "\n",
    "```bash\n",
    "jupyter nbconvert --to notebook --execute backend/scraper/mpv.ipynb --output mpv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/brianrennie/Documents/GitHub/police-data-trust/backend/scraper/notebooks\n",
      "['/Users/brianrennie/Documents/GitHub/police-data-trust/backend/scraper/notebooks', '/Users/brianrennie/.vscode/extensions/ms-toolsai.jupyter-2022.5.1001601848/pythonFiles', '/Users/brianrennie/.vscode/extensions/ms-toolsai.jupyter-2022.5.1001601848/pythonFiles/lib/python', '/opt/homebrew/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python39.zip', '/opt/homebrew/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9', '/opt/homebrew/Cellar/python@3.9/3.9.13_1/Frameworks/Python.framework/Versions/3.9/lib/python3.9/lib-dynload', '', '/Users/brianrennie/Documents/GitHub/police-data-trust/.pdt/lib/python3.9/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "print(os.getcwd())\n",
    "print(sys.path)\n",
    "sys.path.append('/Users/brianrennie/Documents/GitHub/police-data-trust') \n",
    "os.environ['POSTGRES_HOST'] = 'localhost'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T20:04:52.091244Z",
     "iopub.status.busy": "2021-11-15T20:04:52.090739Z",
     "iopub.status.idle": "2021-11-15T20:04:52.684721Z",
     "shell.execute_reply": "2021-11-15T20:04:52.684948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backend.database.core\n"
     ]
    }
   ],
   "source": [
    " \n",
    "import os\n",
    "if os.getcwd().endswith(\"notebooks\"):\n",
    "    # Run this notebook from the repo root\n",
    "    os.chdir(\"../../..\")\n",
    "import sys\n",
    "import math\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "import psycopg2\n",
    "from itertools import zip_longest\n",
    "from typing import List\n",
    "import requests\n",
    "from IPython.display import display, HTML\n",
    "from collections import namedtuple\n",
    "from backend.database import db, Incident, Officer, Accusation, Victim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-15T20:04:52.688209Z",
     "iopub.status.busy": "2021-11-15T20:04:52.687929Z",
     "iopub.status.idle": "2021-11-15T20:04:52.787715Z",
     "shell.execute_reply": "2021-11-15T20:04:52.787455Z"
    }
   },
   "outputs": [],
   "source": [
    "from backend.api import create_app\n",
    "app = create_app(\"development\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Summary\n",
    "\n",
    "- Detailed victim information, incident location, and department responsible\n",
    "- Victim-oriented records; MPV ID's identify victims, and incidents are implied\n",
    "- Low (20%) number of incidents with named officers\n",
    "- Reference WaPo and Fatal Encounters ID's. We have no object to model this now but we can update scraper when appropriate\n",
    "- Findings are less precise than CPDP data. CPDP contains investigation records per-accused officer, while MPV gives a single status for the whole incident. Should we model them differently?\n",
    "\n",
    "So, each MPV record will create 1 victim and 1 incident, and some records will also create officers. We will assume victims are 1-1 with incidents, so that we can use the MPV ID for the source ID of the incident, and unambiguously store the vistims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset\n"
     ]
    }
   ],
   "source": [
    "dataset_url = \"https://docs.google.com/spreadsheets/d/1g7CNEDnjk5dH412wmVTAG6XtgWyS2Vax10-BbfsBp0U/export?format=csv\"\n",
    "dataset_path = \"backend/scraper/data_scrapers/mpv/scraper_data/mpv.csv\"\n",
    "\n",
    "# TODO: Fetch if the file updated. can do with head requests and headers\n",
    "if True:  # not os.path.exists(dataset_path):\n",
    "    print(\"Downloading dataset\")\n",
    "    r = requests.get(dataset_url, stream=True)\n",
    "    with open(dataset_path, \"wb\") as fd:\n",
    "        for chunk in r.iter_content(chunk_size=128):\n",
    "            fd.write(chunk)\n",
    "else:\n",
    "    print(\"Using existing dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['source_id', 'victim_name', 'victim_gender', 'victim_race',\n",
      "       'victim_age', 'victim_image_url', 'manner_of_injury', 'incident_date',\n",
      "       'address', 'city', 'state', 'zip', 'county', 'latitude', 'longitude',\n",
      "       'description', 'officer_outcomes', 'department', 'criminal_charges',\n",
      "       'source_link', 'off_duty_killing', 'encounter_type_draft',\n",
      "       'encounter_reason_draft', 'officer_names_draft', 'officer_races_draft',\n",
      "       'officer_known_past_shootings_draft', 'call_for_service_draft'],\n",
      "      dtype='object')\n",
      "source_id                              object\n",
      "victim_name                            object\n",
      "victim_gender                          object\n",
      "victim_race                            object\n",
      "victim_age                             object\n",
      "victim_image_url                       object\n",
      "manner_of_injury                       object\n",
      "incident_date                          object\n",
      "address                                object\n",
      "city                                   object\n",
      "state                                  object\n",
      "zip                                    object\n",
      "county                                 object\n",
      "latitude                              float64\n",
      "longitude                             float64\n",
      "description                            object\n",
      "officer_outcomes                       object\n",
      "department                             object\n",
      "criminal_charges                       object\n",
      "source_link                            object\n",
      "off_duty_killing                       object\n",
      "encounter_type_draft                   object\n",
      "encounter_reason_draft                 object\n",
      "officer_names_draft                    object\n",
      "officer_races_draft                    object\n",
      "officer_known_past_shootings_draft     object\n",
      "call_for_service_draft                 object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "def map_cols(df, m: dict):\n",
    "    return df[list(m.keys())].rename(columns=m)\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(dataset_path, dtype={\"Zipcode\": str, \"MPV ID\": str}, skiprows=1)\n",
    "dataset = map_cols(\n",
    "    dataset,\n",
    "    {\n",
    "        \"MPV ID\": \"source_id\",\n",
    "        \"Victim's name\": \"victim_name\",\n",
    "        \"Victim's gender\": \"victim_gender\",\n",
    "        \"Victim's race\": \"victim_race\",\n",
    "        \"Victim's age\": \"victim_age\",\n",
    "        \"URL of image of victim\": \"victim_image_url\",\n",
    "        \"Cause of death\": \"manner_of_injury\",\n",
    "        \"Date of Incident (month/day/year)\": \"incident_date\",\n",
    "        \"Street Address of Incident\": \"address\",\n",
    "        \"City\": \"city\",\n",
    "        \"State\": \"state\",\n",
    "        \"Zipcode\": \"zip\",\n",
    "        \"County\": \"county\",\n",
    "        \"Latitude\": \"latitude\",\n",
    "        \"Longitude\": \"longitude\",\n",
    "        \"A brief description of the circumstances surrounding the death\": \"description\",\n",
    "        \"Official disposition of death (justified or other)\": \"officer_outcomes\",\n",
    "        \"Agency responsible for death\": \"department\",\n",
    "        \"Criminal Charges?\": \"criminal_charges\",\n",
    "        \"Link to news article or photo of official document\": \"source_link\",\n",
    "        \"Off-Duty Killing?\": \"off_duty_killing\",\n",
    "        \"Encounter Type (DRAFT)\": \"encounter_type_draft\",\n",
    "        \"Initial Reported Reason for Encounter (DRAFT)\": \"encounter_reason_draft\",\n",
    "        \"Names of Officers Involved (DRAFT)\": \"officer_names_draft\",\n",
    "        \"Race of Officers Involved (DRAFT)\": \"officer_races_draft\",\n",
    "        \"Known Past Shootings of Officer(s) (DRAFT)\": \"officer_known_past_shootings_draft\",\n",
    "        \"Call for Service? (DRAFT)\": \"call_for_service_draft\",\n",
    "    },\n",
    ").set_index(\"source_id\", drop=False)\n",
    "# Some rows are repeated, some ID's seem to be reused.\n",
    "dataset = dataset[~dataset.index.duplicated(keep='first')]\n",
    "assert not dataset.index.has_duplicates\n",
    "\n",
    "print(dataset.columns)\n",
    "print(dataset.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bulk(instances, chunk_size=1000):\n",
    "    \"\"\"Inserts ORM instances into the database\"\"\"\n",
    "    with app.app_context():\n",
    "        for chunk in range(0, len(instances), chunk_size):\n",
    "            db.session.add_all(instances[chunk : chunk + chunk_size])\n",
    "            db.session.flush()\n",
    "        db.session.commit()\n",
    "\n",
    "\n",
    "def isnan(x):\n",
    "    return isinstance(x, float) and math.isnan(x)\n",
    "\n",
    "\n",
    "def nan_to_none(x):\n",
    "    return None if isnan(x) else x\n",
    "\n",
    "\n",
    "def strip_nan(r):\n",
    "    return r._make([nan_to_none(e) for e in r])\n",
    "\n",
    "\n",
    "def map_df(df, mapper):\n",
    "    return [mapper(strip_nan(r)) for r in df.itertuples(index=False)]\n",
    "\n",
    "\n",
    "def parse_int(value):\n",
    "    try:\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def location(r: namedtuple):\n",
    "    return \" \".join(filter(None, [r.address, r.city, r.state, r.zip]))\n",
    "\n",
    "\n",
    "def parse_parts(s: str):\n",
    "    return list(map(lambda x: x.strip(), s.split(\",\"))) if s else []\n",
    "\n",
    "\n",
    "def parse_officers(r: namedtuple):\n",
    "    names = parse_parts(r.officer_names_draft)\n",
    "    races = parse_parts(r.officer_races_draft)\n",
    "\n",
    "    return [\n",
    "        Officer(last_name=name, race=race)\n",
    "        for name, race in zip_longest(names, races)\n",
    "    ]\n",
    "\n",
    "\n",
    "def parse_accusations(r: namedtuple, officers: List[Officer]):\n",
    "    outcomes = parse_parts(r.officer_outcomes)\n",
    "    return [\n",
    "        Accusation(outcome=outcome, officer=officer)\n",
    "        for officer, outcome in zip_longest(officers, outcomes)\n",
    "    ]\n",
    "\n",
    "\n",
    "def create_orm(r: namedtuple):\n",
    "    breakpoint()\n",
    "    victim = Victim(\n",
    "        name=r.victim_name,\n",
    "        race=r.victim_race,\n",
    "        gender=r.victim_gender,\n",
    "        manner_of_injury=r.manner_of_injury,\n",
    "        deceased=True,\n",
    "    )\n",
    "    officers = parse_officers(r)\n",
    "    accusations = parse_accusations(r, officers)\n",
    "    incident = Incident(\n",
    "        source_id=r.source_id,\n",
    "        source=\"mpv\",\n",
    "        time_of_incident=r.incident_date,\n",
    "        location=location(r),\n",
    "        description=r.description,\n",
    "        department=r.department,\n",
    "        # latitude=r.latitude,\n",
    "        # longitude=r.longitude,\n",
    "        victims=[victim],\n",
    "        officers=officers,\n",
    "        accusations=accusations,\n",
    "    )\n",
    "    \n",
    "    print(incident)\n",
    "    return incident\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Incident (transient 5082079040)>\n",
      "[<Incident (transient 5082079040)>]\n",
      "Found 9925 existing records. Creating 1 new incidents\n"
     ]
    }
   ],
   "source": [
    "with app.app_context():\n",
    "    existing_source_ids = list(\n",
    "        s\n",
    "        for (s,) in db.session.query(Incident.source_id).filter(\n",
    "            Incident.source == \"mpv\", Incident.source_id != None\n",
    "        )\n",
    "    )\n",
    "new_data = dataset.drop(existing_source_ids)\n",
    "incidents = map_df(new_data, create_orm)\n",
    "print(incidents)\n",
    "print(f\"Found {len(existing_source_ids)} existing records. Creating {len(incidents)} new incidents\")\n",
    "create_bulk(incidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "47c4521dfd0b677aadf842e1db7c0cfc67273c205cec7945eb2bb7409ec58d6a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.pdt': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
